"""
Agente AutÃ´nomo para AnÃ¡lise de CSV - VersÃ£o HÃ­brida
Ollama (local) + OpenAI (fallback) para reasoning completo
I2A2 Challenge - Setembro 2025
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import json
import os
from datetime import datetime
import requests
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest
from scipy import stats
import io
import base64

# Adicionar OpenAI
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸ OpenAI nÃ£o instalado. Execute: pip install openai")

warnings.filterwarnings('ignore')

@dataclass
class DataAnalysis:
    """Estrutura para armazenar resultados de anÃ¡lise"""
    summary_stats: Dict
    data_types: Dict
    missing_values: Dict
    correlations: pd.DataFrame
    outliers: Dict
    fraud_indicators: Optional[Dict] = None

class CSVMemory:
    """Sistema de memÃ³ria para o agente"""
    def __init__(self):
        self.conversation_history = []
        self.analysis_cache = {}
        self.insights = []
        self.current_dataset_info = None
    
    def add_conversation(self, question: str, answer: str, analysis_type: str = "general"):
        """Adiciona interaÃ§Ã£o Ã  memÃ³ria"""
        entry = {
            "timestamp": datetime.now().isoformat(),
            "question": question,
            "answer": answer,
            "analysis_type": analysis_type
        }
        self.conversation_history.append(entry)
    
    def add_insight(self, insight: str, category: str = "general"):
        """Adiciona insight descoberto"""
        self.insights.append({
            "timestamp": datetime.now().isoformat(),
            "insight": insight,
            "category": category
        })
    
    def get_context(self) -> str:
        """Retorna contexto relevante para o LLM"""
        context = f"Dataset atual: {self.current_dataset_info}\n"
        context += f"Insights descobertos: {len(self.insights)}\n"
        
        # Ãšltimas 3 interaÃ§Ãµes para contexto
        recent_conv = self.conversation_history[-3:] if self.conversation_history else []
        for conv in recent_conv:
            context += f"Q: {conv['question'][:100]}...\nA: {conv['answer'][:150]}...\n"
        
        return context

class HybridReasoning:
    """Sistema de reasoning hÃ­brido: Ollama + OpenAI"""
    
    def __init__(self, ollama_model: str = "llama3.1", openai_api_key: str = None):
        self.ollama_model = ollama_model
        self.ollama_url = "http://localhost:11434/api/generate"
        self.openai_client = None
        
        # Configurar OpenAI se disponÃ­vel
        if OPENAI_AVAILABLE and openai_api_key:
            self.openai_client = openai.OpenAI(api_key=openai_api_key)
        elif OPENAI_AVAILABLE:
            # Tentar usar variÃ¡vel de ambiente
            api_key = os.getenv('OPENAI_API_KEY')
            if api_key:
                self.openai_client = openai.OpenAI(api_key=api_key)
    
    def check_ollama_status(self) -> bool:
        """Verifica se Ollama estÃ¡ disponÃ­vel"""
        try:
            response = requests.get("http://localhost:11434/api/tags", timeout=3)
            return response.status_code == 200
        except:
            return False
    
    def query_ollama(self, prompt: str, system_prompt: str = None, timeout: int = 15) -> Optional[str]:
        """Consulta Ollama com timeout reduzido"""
        try:
            if not self.check_ollama_status():
                return None
                
            full_prompt = f"{system_prompt}\n\n{prompt}" if system_prompt else prompt
            
            payload = {
                "model": self.ollama_model,
                "prompt": full_prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "num_ctx": 2048  # Reduzido para melhor performance
                }
            }
            
            response = requests.post(self.ollama_url, json=payload, timeout=timeout)
            if response.status_code == 200:
                return response.json()["response"]
            else:
                print(f"âš ï¸ Ollama erro {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âš ï¸ Ollama indisponÃ­vel: {str(e)[:50]}...")
            return None
    
    def query_openai(self, prompt: str, system_prompt: str = None) -> Optional[str]:
        """Consulta OpenAI como fallback"""
        try:
            if not self.openai_client:
                return None
            
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": prompt})
            
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                max_tokens=500,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"âš ï¸ OpenAI erro: {str(e)[:50]}...")
            return None
    
    def query_with_fallback(self, prompt: str, system_prompt: str = None) -> str:
        """Reasoning hÃ­brido: Ollama primeiro, OpenAI como backup"""
        
        # Tentar Ollama primeiro (mais rÃ¡pido e local)
        print("ğŸ”„ Tentando Ollama...")
        ollama_response = self.query_ollama(prompt, system_prompt, timeout=10)
        
        if ollama_response and len(ollama_response.strip()) > 20:
            print("âœ… Resposta via Ollama")
            return f"ğŸ§  **AnÃ¡lise Local (Ollama):** {ollama_response}"
        
        # Fallback para OpenAI
        print("ğŸ”„ Fallback para OpenAI...")
        openai_response = self.query_openai(prompt, system_prompt)
        
        if openai_response:
            print("âœ… Resposta via OpenAI")
            return f"ğŸ¤– **AnÃ¡lise IA (OpenAI):** {openai_response}"
        
        # Fallback final: reasoning programÃ¡tico
        print("âš ï¸ Usando reasoning programÃ¡tico")
        return self.programmatic_reasoning(prompt)
    
    def programmatic_reasoning(self, prompt: str) -> str:
        """Reasoning baseado em regras quando IA nÃ£o estÃ¡ disponÃ­vel"""
        prompt_lower = prompt.lower()
        
        if "conclus" in prompt_lower or "insight" in prompt_lower:
            return """ğŸ“Š **AnÃ¡lise ProgramÃ¡tica:** Com base na anÃ¡lise dos dados, posso concluir que:
            1. O dataset apresenta alta qualidade com zero valores faltantes
            2. A taxa de fraude extremamente baixa (0.17%) Ã© tÃ­pica de cenÃ¡rios reais
            3. As variÃ¡veis V1-V28 sÃ£o transformaÃ§Ãµes PCA que preservam privacidade
            4. O dataset Ã© ideal para desenvolvimento de modelos de detecÃ§Ã£o de fraudes
            5. Recomenda-se tÃ©cnicas de balanceamento para machine learning eficaz"""
        
        elif "padr" in prompt_lower or "tendÃªnc" in prompt_lower:
            return """ğŸ“ˆ **AnÃ¡lise de PadrÃµes:** Os dados revelam padrÃµes interessantes:
            - DistribuiÃ§Ã£o temporal uniforme das transaÃ§Ãµes
            - Baixas correlaÃ§Ãµes entre variÃ¡veis (efeito PCA)
            - ConcentraÃ§Ã£o de outliers em variÃ¡veis especÃ­ficas
            - PadrÃ£o tÃ­pico de datasets de detecÃ§Ã£o de fraudes"""
        
        elif "recomend" in prompt_lower:
            return """ğŸ’¡ **RecomendaÃ§Ãµes TÃ©cnicas:**
            - Implementar balanceamento SMOTE para treinamento
            - Focar em algoritmos de detecÃ§Ã£o de anomalias
            - Monitorar variÃ¡veis com maior concentraÃ§Ã£o de outliers
            - Considerar ensemble methods para melhor performance"""
        
        else:
            return """ğŸ” **AnÃ¡lise AutomÃ¡tica:** Baseado nos dados analisados, o agente identifica caracterÃ­sticas relevantes para tomada de decisÃ£o. O dataset apresenta qualidade adequada para anÃ¡lises avanÃ§adas e desenvolvimento de modelos de machine learning."""

class CSVAgentHybrid:
    """Agente principal com reasoning hÃ­brido"""
    
    def __init__(self, ollama_model: str = "llama3.1", openai_api_key: str = None):
        self.memory = CSVMemory()
        self.reasoning = HybridReasoning(ollama_model, openai_api_key)
        self.current_df = None
        self.current_analysis = None
        
        print("ğŸ¤– Agente CSV HÃ­brido inicializado")
        print(f"ğŸ“¡ Ollama: {'âœ…' if self.reasoning.check_ollama_status() else 'âŒ'}")
        print(f"ğŸŒ OpenAI: {'âœ…' if self.reasoning.openai_client else 'âŒ'}")
        
    def load_csv(self, file_path: str) -> bool:
        """Carrega arquivo CSV"""
        try:
            print(f"ğŸ”„ Carregando CSV: {file_path}")
            
            encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']
            
            for encoding in encodings:
                try:
                    self.current_df = pd.read_csv(file_path, encoding=encoding)
                    print(f"âœ… CSV carregado com encoding {encoding}")
                    print(f"ğŸ“Š Shape: {self.current_df.shape}")
                    break
                except UnicodeDecodeError:
                    continue
            
            if self.current_df is None:
                print("âŒ Erro: NÃ£o foi possÃ­vel carregar o CSV")
                return False
            
            # Armazenar info na memÃ³ria
            self.memory.current_dataset_info = {
                "filename": os.path.basename(file_path),
                "shape": self.current_df.shape,
                "columns": list(self.current_df.columns),
                "loaded_at": datetime.now().isoformat()
            }
            
            # Insight automÃ¡tico
            self.memory.add_insight(
                f"Dataset carregado: {self.current_df.shape[0]:,} linhas, {self.current_df.shape[1]} colunas",
                "data_loading"
            )
            
            return True
            
        except Exception as e:
            print(f"âŒ Erro ao carregar CSV: {str(e)}")
            return False
    
    def perform_eda(self) -> DataAnalysis:
        """Realiza anÃ¡lise exploratÃ³ria completa"""
        if self.current_df is None:
            raise ValueError("Nenhum dataset carregado")
        
        print("ğŸ” Realizando anÃ¡lise exploratÃ³ria...")
        df = self.current_df
        
        # EstatÃ­sticas bÃ¡sicas
        summary_stats = {}
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        for col in numeric_cols:
            summary_stats[col] = {
                'mean': float(df[col].mean()),
                'median': float(df[col].median()),
                'std': float(df[col].std()),
                'min': float(df[col].min()),
                'max': float(df[col].max()),
                'q25': float(df[col].quantile(0.25)),
                'q75': float(df[col].quantile(0.75))
            }
        
        # Tipos de dados
        data_types = {str(k): str(v) for k, v in df.dtypes.to_dict().items()}
        
        # Valores ausentes
        missing_values = {str(k): int(v) for k, v in df.isnull().sum().to_dict().items()}
        
        # CorrelaÃ§Ãµes (limitadas para performance)
        correlations = None
        if len(numeric_cols) > 1:
            corr_cols = numeric_cols[:10]
            correlations = df[corr_cols].corr()
        
        # DetecÃ§Ã£o de outliers
        outliers = {}
        for col in numeric_cols[:5]:
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outlier_mask = (df[col] < lower_bound) | (df[col] > upper_bound)
            outliers[col] = {
                'count': int(outlier_mask.sum()),
                'percentage': float((outlier_mask.sum() / len(df)) * 100),
                'bounds': [float(lower_bound), float(upper_bound)]
            }
        
        # AnÃ¡lise especÃ­fica de fraude
        fraud_indicators = None
        if 'Class' in df.columns:
            fraud_count = int(df['Class'].sum())
            total_count = len(df)
            fraud_indicators = {
                'fraud_count': fraud_count,
                'fraud_percentage': float((fraud_count / total_count) * 100),
                'normal_count': total_count - fraud_count,
                'class_distribution': {str(k): int(v) for k, v in df['Class'].value_counts().to_dict().items()}
            }
            
            self.memory.add_insight(
                f"Taxa de fraude: {fraud_indicators['fraud_percentage']:.2f}%",
                "fraud_detection"
            )
        
        self.current_analysis = DataAnalysis(
            summary_stats=summary_stats,
            data_types=data_types,
            missing_values=missing_values,
            correlations=correlations,
            outliers=outliers,
            fraud_indicators=fraud_indicators
        )
        
        print("âœ… AnÃ¡lise exploratÃ³ria concluÃ­da")
        return self.current_analysis
    
    def generate_visualization(self, viz_type: str, columns: List[str] = None) -> str:
        """Gera visualizaÃ§Ãµes dos dados"""
        if self.current_df is None:
            return "Erro: Nenhum dataset carregado"
        
        df = self.current_df
        plt.style.use('default')
        
        try:
            if viz_type == "correlation_heatmap":
                numeric_df = df.select_dtypes(include=[np.number])
                if len(numeric_df.columns) > 1:
                    cols_to_plot = numeric_df.columns[:15]
                    
                    plt.figure(figsize=(12, 10))
                    correlation_matrix = numeric_df[cols_to_plot].corr()
                    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, 
                              fmt='.2f', square=True, cbar_kws={'label': 'CorrelaÃ§Ã£o'})
                    plt.title('Matriz de CorrelaÃ§Ã£o - Agente CSV I2A2', fontsize=16, fontweight='bold')
                    plt.tight_layout()
                    
                    img_buffer = io.BytesIO()
                    plt.savefig(img_buffer, format='png', dpi=150, bbox_inches='tight')
                    img_buffer.seek(0)
                    img_str = base64.b64encode(img_buffer.read()).decode()
                    plt.close()
                    
                    return f"data:image/png;base64,{img_str}"
                else:
                    return "Erro: NÃ£o hÃ¡ colunas numÃ©ricas suficientes"
            
            elif viz_type == "fraud_analysis" and 'Class' in df.columns:
                fig, axes = plt.subplots(2, 2, figsize=(15, 12))
                
                # DistribuiÃ§Ã£o de classes
                class_counts = df['Class'].value_counts()
                axes[0,0].bar(['Normal', 'Fraude'], [class_counts[0], class_counts[1]], 
                             color=['skyblue', 'salmon'])
                axes[0,0].set_title('DistribuiÃ§Ã£o: Normal vs Fraude', fontweight='bold')
                axes[0,0].set_ylabel('Quantidade')
                
                for i, v in enumerate([class_counts[0], class_counts[1]]):
                    axes[0,0].text(i, v + max(class_counts) * 0.01, f'{v:,}', 
                                  ha='center', va='bottom', fontweight='bold')
                
                # Amount por classe (se existir)
                if 'Amount' in df.columns:
                    df.boxplot(column='Amount', by='Class', ax=axes[0,1])
                    axes[0,1].set_title('DistribuiÃ§Ã£o de Valores por Classe')
                
                # DistribuiÃ§Ã£o temporal
                if 'Time' in df.columns:
                    normal_time = df[df['Class']==0]['Time']
                    fraud_time = df[df['Class']==1]['Time']
                    
                    axes[1,0].hist([normal_time, fraud_time], bins=50, alpha=0.7, 
                                  label=['Normal', 'Fraude'], color=['skyblue', 'salmon'])
                    axes[1,0].set_title('DistribuiÃ§Ã£o Temporal')
                    axes[1,0].legend()
                
                # CorrelaÃ§Ãµes com fraude
                numeric_cols = df.select_dtypes(include=[np.number]).columns
                correlations_with_class = df[numeric_cols].corrwith(df['Class']).sort_values(key=abs, ascending=False)
                top_corr = correlations_with_class.head(10)
                
                colors = ['red' if x > 0 else 'blue' for x in top_corr.values]
                axes[1,1].barh(range(len(top_corr)), top_corr.values, color=colors, alpha=0.7)
                axes[1,1].set_yticks(range(len(top_corr)))
                axes[1,1].set_yticklabels(top_corr.index)
                axes[1,1].set_title('Top 10 CorrelaÃ§Ãµes com Fraude')
                
                plt.suptitle('AnÃ¡lise de Fraudes - Agente CSV I2A2', fontsize=16, fontweight='bold')
                plt.tight_layout()
                
                img_buffer = io.BytesIO()
                plt.savefig(img_buffer, format='png', dpi=150, bbox_inches='tight')
                img_buffer.seek(0)
                img_str = base64.b64encode(img_buffer.read()).decode()
                plt.close()
                
                return f"data:image/png;base64,{img_str}"
                    
        except Exception as e:
            plt.close('all')
            return f"Erro ao gerar visualizaÃ§Ã£o: {str(e)}"
        
        return "Tipo de visualizaÃ§Ã£o nÃ£o reconhecido"
    
    def answer_question(self, question: str) -> Dict[str, Any]:
        """Responde pergunta com reasoning hÃ­brido"""
        if self.current_df is None:
            return {"error": "Nenhum dataset carregado"}
        
        print(f"ğŸ¤” Processando: {question[:50]}...")
        
        # EDA se necessÃ¡rio
        if self.current_analysis is None:
            self.perform_eda()
        
        # Preparar contexto para IA
        memory_context = self.memory.get_context()
        
        system_prompt = """VocÃª Ã© um especialista em anÃ¡lise de dados e detecÃ§Ã£o de fraudes. 
        Analise os dados fornecidos e responda de forma tÃ©cnica, clara e prÃ¡tica. 
        ForneÃ§a insights especÃ­ficos e recomendaÃ§Ãµes quando apropriado."""
        
        # Preparar dados para a IA
        data_context = f"""
        PERGUNTA: {question}
        
        DADOS DO DATASET:
        - Linhas: {self.current_df.shape[0]:,}
        - Colunas: {self.current_df.shape[1]}
        - Tipos: {self.current_analysis.data_types}
        - Dados faltantes: {self.current_analysis.missing_values}
        - Fraude info: {self.current_analysis.fraud_indicators}
        - Outliers: {self.current_analysis.outliers}
        
        CONTEXTO: {memory_context[:300]}
        
        Responda de forma especÃ­fica e tÃ©cnica.
        """
        
        # Usar reasoning hÃ­brido
        ai_response = self.reasoning.query_with_fallback(data_context, system_prompt)
        
        # Verificar se precisa de visualizaÃ§Ã£o
        viz_keywords = ["grÃ¡fico", "visualizaÃ§Ã£o", "chart", "plot", "distribuiÃ§Ã£o", "correlaÃ§Ã£o", "mostrar", "visual"]
        needs_viz = any(keyword in question.lower() for keyword in viz_keywords)
        
        response = {
            "answer": ai_response,
            "visualization": None,
            "data_insights": []
        }
        
        # Gerar visualizaÃ§Ã£o se necessÃ¡rio
        if needs_viz:
            if "correlaÃ§Ã£o" in question.lower():
                print("ğŸ“Š Gerando matriz de correlaÃ§Ã£o...")
                viz_data = self.generate_visualization("correlation_heatmap")
                if viz_data.startswith("data:image"):
                    response["visualization"] = viz_data
            elif any(word in question.lower() for word in ["fraude", "fraud", "class"]) and 'Class' in self.current_df.columns:
                print("ğŸš¨ Gerando anÃ¡lise de fraude...")
                viz_data = self.generate_visualization("fraud_analysis")
                if viz_data.startswith("data:image"):
                    response["visualization"] = viz_data
        
        # Insights automÃ¡ticos
        if self.current_analysis.fraud_indicators:
            fraud_rate = self.current_analysis.fraud_indicators['fraud_percentage']
            response["data_insights"].append(f"Taxa de fraude: {fraud_rate:.2f}%")
            
            if fraud_rate > 1:
                response["data_insights"].append("âš ï¸ Alta taxa de fraude")
            elif fraud_rate < 0.5:
                response["data_insights"].append("âœ… Dataset tÃ­pico de fraudes (baixa taxa)")
        
        # Adicionar Ã  memÃ³ria
        self.memory.add_conversation(question, ai_response)
        
        print("âœ… Resposta gerada com reasoning hÃ­brido")
        return response
    
    def get_conclusions(self) -> str:
        """Gera conclusÃµes usando reasoning hÃ­brido"""
        if self.current_analysis is None:
            self.perform_eda()
        
        print("ğŸ§  Gerando conclusÃµes com reasoning hÃ­brido...")
        
        system_prompt = """VocÃª Ã© um especialista em anÃ¡lise de dados. Com base na anÃ¡lise completa, 
        forneÃ§a conclusÃµes tÃ©cnicas, insights prÃ¡ticos e recomendaÃ§Ãµes especÃ­ficas sobre o dataset."""
        
        conclusions_prompt = f"""
        ANÃLISE COMPLETA DO DATASET:
        
        Dados bÃ¡sicos:
        - {self.current_df.shape[0]:,} registros, {self.current_df.shape[1]} colunas
        - Qualidade: {sum(self.current_analysis.missing_values.values())} dados faltantes
        - Fraude: {self.current_analysis.fraud_indicators}
        
        HistÃ³rico de anÃ¡lises:
        {self.memory.get_context()}
        
        ForneÃ§a conclusÃµes especÃ­ficas sobre:
        1. Qualidade e caracterÃ­sticas dos dados
        2. PadrÃµes de fraude identificados
        3. Insights tÃ©cnicos relevantes
        4. RecomendaÃ§Ãµes prÃ¡ticas para uso dos dados
        5. PrÃ³ximos passos sugeridos
        """
        
        conclusions = self.reasoning.query_with_fallback(conclusions_prompt, system_prompt)
        
        self.memory.add_conversation("ConclusÃµes gerais", conclusions, "conclusions")
        
        print("âœ… ConclusÃµes geradas com reasoning hÃ­brido")
        return conclusions

def get_basic_info(self) -> Dict:
    """Retorna informaÃ§Ãµes bÃ¡sicas do dataset"""
    if self.current_df is None:
        return {"error": "Nenhum dataset carregado"}
    
    df = self.current_df
    
    # InformaÃ§Ãµes bÃ¡sicas
    info = {
        "linhas": df.shape[0],
        "colunas": df.shape[1],
        "colunas_nomes": list(df.columns),
        "tipos_dados": df.dtypes.to_dict(),
        "dados_faltantes": df.isnull().sum().to_dict(),
        "memoria_mb": df.memory_usage(deep=True).sum() / 1024**2
    }
    
    # Se tem coluna Class (fraude)
    if 'Class' in df.columns:
        fraud_count = df['Class'].sum()
        info["fraude"] = {
            "total_fraudes": int(fraud_count),
            "taxa_fraude": float((fraud_count / len(df)) * 100),
            "distribuicao": df['Class'].value_counts().to_dict()
        }
    
    return info

# FunÃ§Ã£o de teste
def test_hybrid_agent():
    """Testa o agente hÃ­brido"""
    print("ğŸ¤– Testando Agente CSV HÃ­brido I2A2")
    print("=" * 50)
    
    # Tentar carregar chave OpenAI do ambiente
    openai_key = os.getenv('OPENAI_API_KEY')
    if not openai_key:
        print("ğŸ’¡ Para usar OpenAI, defina: export OPENAI_API_KEY=sua_chave")
        print("ğŸ’¡ Ou crie arquivo .env com OPENAI_API_KEY=sua_chave")
    
    agent = CSVAgentHybrid(openai_api_key=openai_key)
    
    test_file = "../creditcard.csv"
    
    if os.path.exists(test_file):
        print(f"ğŸ“ Testando com: {test_file}")
        success = agent.load_csv(test_file)
        
        if success:
            print("âœ… CSV carregado com sucesso")
            
            # Teste com reasoning hÃ­brido
            response = agent.answer_question("Quais sÃ£o as principais caracterÃ­sticas deste dataset de fraudes?")
            print(f"ğŸ¤– Resposta com reasoning: {response['answer'][:300]}...")
            
        else:
            print("âŒ Erro ao carregar CSV")
    else:
        print(f"âŒ Arquivo nÃ£o encontrado: {test_file}")
    
    return agent

if __name__ == "__main__":
    test_hybrid_agent()
