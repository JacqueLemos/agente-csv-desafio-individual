"""
Agente Autônomo para Análise de CSV - Versão Híbrida
Ollama (local) + OpenAI (fallback) para reasoning completo
I2A2 Challenge - Setembro 2025
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import json
import os
from datetime import datetime
import requests
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest
from scipy import stats
import io
import base64

# Adicionar OpenAI
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("⚠️ OpenAI não instalado. Execute: pip install openai")

warnings.filterwarnings('ignore')

@dataclass
class DataAnalysis:
    """Estrutura para armazenar resultados de análise"""
    summary_stats: Dict
    data_types: Dict
    missing_values: Dict
    correlations: pd.DataFrame
    outliers: Dict
    fraud_indicators: Optional[Dict] = None

class CSVMemory:
    """Sistema de memória para o agente"""
    def __init__(self):
        self.conversation_history = []
        self.analysis_cache = {}
        self.insights = []
        self.current_dataset_info = None
    
    def add_conversation(self, question: str, answer: str, analysis_type: str = "general"):
        """Adiciona interação à memória"""
        entry = {
            "timestamp": datetime.now().isoformat(),
            "question": question,
            "answer": answer,
            "analysis_type": analysis_type
        }
        self.conversation_history.append(entry)
    
    def add_insight(self, insight: str, category: str = "general"):
        """Adiciona insight descoberto"""
        self.insights.append({
            "timestamp": datetime.now().isoformat(),
            "insight": insight,
            "category": category
        })
    
    def get_context(self) -> str:
        """Retorna contexto relevante para o LLM"""
        context = f"Dataset atual: {self.current_dataset_info}\n"
        context += f"Insights descobertos: {len(self.insights)}\n"
        
        # Últimas 3 interações para contexto
        recent_conv = self.conversation_history[-3:] if self.conversation_history else []
        for conv in recent_conv:
            context += f"Q: {conv['question'][:100]}...\nA: {conv['answer'][:150]}...\n"
        
        return context

class HybridReasoning:
    """Sistema de reasoning híbrido: Ollama + OpenAI"""
    
    def __init__(self, ollama_model: str = "llama3.1", openai_api_key: str = None):
        self.ollama_model = ollama_model
        self.ollama_url = "http://localhost:11434/api/generate"
        self.openai_client = None
        
        # Configurar OpenAI se disponível
        if OPENAI_AVAILABLE and openai_api_key:
            self.openai_client = openai.OpenAI(api_key=openai_api_key)
        elif OPENAI_AVAILABLE:
            # Tentar usar variável de ambiente
            api_key = os.getenv('OPENAI_API_KEY')
            if api_key:
                self.openai_client = openai.OpenAI(api_key=api_key)
    
    def check_ollama_status(self) -> bool:
        """Verifica se Ollama está disponível"""
        try:
            response = requests.get("http://localhost:11434/api/tags", timeout=3)
            return response.status_code == 200
        except:
            return False
    
    def query_ollama(self, prompt: str, system_prompt: str = None, timeout: int = 15) -> Optional[str]:
        """Consulta Ollama com timeout reduzido"""
        try:
            if not self.check_ollama_status():
                return None
                
            full_prompt = f"{system_prompt}\n\n{prompt}" if system_prompt else prompt
            
            payload = {
                "model": self.ollama_model,
                "prompt": full_prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "num_ctx": 2048  # Reduzido para melhor performance
                }
            }
            
            response = requests.post(self.ollama_url, json=payload, timeout=timeout)
            if response.status_code == 200:
                return response.json()["response"]
            else:
                print(f"⚠️ Ollama erro {response.status_code}")
                return None
                
        except Exception as e:
            print(f"⚠️ Ollama indisponível: {str(e)[:50]}...")
            return None
    
    def query_openai(self, prompt: str, system_prompt: str = None) -> Optional[str]:
        """Consulta OpenAI como fallback"""
        try:
            if not self.openai_client:
                return None
            
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": prompt})
            
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                max_tokens=500,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"⚠️ OpenAI erro: {str(e)[:50]}...")
            return None
    
    def query_with_fallback(self, prompt: str, system_prompt: str = None) -> str:
        """Reasoning híbrido: Ollama primeiro, OpenAI como backup"""
        
        # Tentar Ollama primeiro (mais rápido e local)
        print("🔄 Tentando Ollama...")
        ollama_response = self.query_ollama(prompt, system_prompt, timeout=10)
        
        if ollama_response and len(ollama_response.strip()) > 20:
            print("✅ Resposta via Ollama")
            return f"🧠 **Análise Local (Ollama):** {ollama_response}"
        
        # Fallback para OpenAI
        print("🔄 Fallback para OpenAI...")
        openai_response = self.query_openai(prompt, system_prompt)
        
        if openai_response:
            print("✅ Resposta via OpenAI")
            return f"🤖 **Análise IA (OpenAI):** {openai_response}"
        
        # Fallback final: reasoning programático
        print("⚠️ Usando reasoning programático")
        return self.programmatic_reasoning(prompt)
    
    def programmatic_reasoning(self, prompt: str, analysis_data: DataAnalysis = None) -> str:
        """Reasoning baseado em regras com dados reais"""
        prompt_lower = prompt.lower()
        
        if "outlier" in prompt_lower and analysis_data:
            outlier_info = []
            for col, data in analysis_data.outliers.items():
                outlier_info.append(f"{col}: {data['count']:,} ({data['percentage']:.1f}%)")
            
            if outlier_info:
                return f"""📊 **Análise de Outliers:** Detectados outliers em {len(outlier_info)} colunas:
                {' | '.join(outlier_info[:5])}
                
                As variáveis V1-V28 com outliers podem indicar padrões atípicos relevantes para detecção de fraudes."""
        
        elif "correlação" in prompt_lower and analysis_data and analysis_data.correlations is not None:
            corr_matrix = analysis_data.correlations
            max_corr = corr_matrix.abs().unstack().sort_values(ascending=False)
            max_corr = max_corr[max_corr < 1.0].head(3)
            
            return f"""📈 **Análise de Correlação:** Principais correlações encontradas:
            {' | '.join([f'{idx[0]}-{idx[1]}: {val:.3f}' for idx, val in max_corr.items()])}
            
            Baixas correlações confirmam eficácia da transformação PCA para preservar privacidade."""
        
        elif "fraude" in prompt_lower and analysis_data and analysis_data.fraud_indicators:
            fraud_info = analysis_data.fraud_indicators
            return f"""🚨 **Análise de Fraude:** 
            - Total de fraudes: {fraud_info['fraud_count']:,} casos
            - Taxa de fraude: {fraud_info['fraud_percentage']:.3f}%
            - Transações normais: {fraud_info['normal_count']:,}
            
            Taxa extremamente baixa indica dataset real típico de sistemas de pagamento."""
        
        elif "dados faltantes" in prompt_lower and analysis_data:
            missing_total = sum(analysis_data.missing_values.values())
            if missing_total == 0:
                return """✅ **Qualidade dos Dados:** Zero valores faltantes em todas as colunas.
                Dataset de alta qualidade, pronto para análises sem necessidade de imputação."""
            else:
                missing_cols = {k: v for k, v in analysis_data.missing_values.items() if v > 0}
                return f"""⚠️ **Dados Faltantes:** {missing_total:,} valores ausentes em {len(missing_cols)} colunas:
                {' | '.join([f'{k}: {v}' for k, v in list(missing_cols.items())[:3]])}"""
        
        elif "conclus" in prompt_lower or "insight" in prompt_lower:
            insights = []
            if analysis_data:
                if analysis_data.fraud_indicators:
                    rate = analysis_data.fraud_indicators['fraud_percentage']
                    insights.append(f"Taxa de fraude: {rate:.3f}% (típica de cenários reais)")
                
                missing_total = sum(analysis_data.missing_values.values())
                if missing_total == 0:
                    insights.append("Dataset limpo sem valores faltantes")
                
                outlier_cols = len([col for col, data in analysis_data.outliers.items() if data['count'] > 0])
                insights.append(f"Outliers detectados em {outlier_cols} colunas")
            
            return f"""📊 **Conclusões Técnicas:**
            {' | '.join(insights)}
            
            Recomendações: Usar técnicas de balanceamento para ML, focar em detecção de anomalias, 
            monitorar variáveis com outliers para identificação de padrões fraudulentos."""
        
        else:
            return """🔍 **Análise Automática:** Dataset analisado com sucesso. 
            Para insights específicos, pergunte sobre outliers, correlações, fraudes ou conclusões."""

class CSVAgentHybrid:
    """Agente principal com reasoning híbrido"""
    
    def __init__(self, ollama_model: str = "llama3.1", openai_api_key: str = None):
        self.memory = CSVMemory()
        self.reasoning = HybridReasoning(ollama_model, openai_api_key)
        self.current_df = None
        self.current_analysis = None
        
        print("🤖 Agente CSV Híbrido inicializado")
        print(f"📡 Ollama: {'✅' if self.reasoning.check_ollama_status() else '❌'}")
        print(f"🌐 OpenAI: {'✅' if self.reasoning.openai_client else '❌'}")
        
    def load_csv(self, file_path: str) -> bool:
        """Carrega arquivo CSV"""
        try:
            print(f"🔄 Carregando CSV: {file_path}")
            
            encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']
            
            for encoding in encodings:
                try:
                    self.current_df = pd.read_csv(file_path, encoding=encoding)
                    print(f"✅ CSV carregado com encoding {encoding}")
                    print(f"📊 Shape: {self.current_df.shape}")
                    break
                except UnicodeDecodeError:
                    continue
            
            if self.current_df is None:
                print("❌ Erro: Não foi possível carregar o CSV")
                return False
            
            # Armazenar info na memória
            self.memory.current_dataset_info = {
                "filename": os.path.basename(file_path),
                "shape": self.current_df.shape,
                "columns": list(self.current_df.columns),
                "loaded_at": datetime.now().isoformat()
            }
            
            # Insight automático
            self.memory.add_insight(
                f"Dataset carregado: {self.current_df.shape[0]:,} linhas, {self.current_df.shape[1]} colunas",
                "data_loading"
            )
            
            return True
            
        except Exception as e:
            print(f"❌ Erro ao carregar CSV: {str(e)}")
            return False
    
    def perform_eda(self) -> DataAnalysis:
        """Realiza análise exploratória completa"""
        if self.current_df is None:
            raise ValueError("Nenhum dataset carregado")
        
        print("🔍 Realizando análise exploratória...")
        df = self.current_df
        
        # Estatísticas básicas
        summary_stats = {}
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        for col in numeric_cols:
            summary_stats[col] = {
                'mean': float(df[col].mean()),
                'median': float(df[col].median()),
                'std': float(df[col].std()),
                'min': float(df[col].min()),
                'max': float(df[col].max()),
                'q25': float(df[col].quantile(0.25)),
                'q75': float(df[col].quantile(0.75))
            }
        
        # Tipos de dados
        data_types = {str(k): str(v) for k, v in df.dtypes.to_dict().items()}
        
        # Valores ausentes
        missing_values = {str(k): int(v) for k, v in df.isnull().sum().to_dict().items()}
        
        # Correlações (limitadas para performance)
        correlations = None
        if len(numeric_cols) > 1:
            corr_cols = numeric_cols[:10]
            correlations = df[corr_cols].corr()
        
        # Detecção de outliers
        outliers = {}
        for col in numeric_cols[:5]:
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outlier_mask = (df[col] < lower_bound) | (df[col] > upper_bound)
            outliers[col] = {
                'count': int(outlier_mask.sum()),
                'percentage': float((outlier_mask.sum() / len(df)) * 100),
                'bounds': [float(lower_bound), float(upper_bound)]
            }
        
        # Análise específica de fraude
        fraud_indicators = None
        if 'Class' in df.columns:
            fraud_count = int(df['Class'].sum())
            total_count = len(df)
            fraud_indicators = {
                'fraud_count': fraud_count,
                'fraud_percentage': float((fraud_count / total_count) * 100),
                'normal_count': total_count - fraud_count,
                'class_distribution': {str(k): int(v) for k, v in df['Class'].value_counts().to_dict().items()}
            }
            
            self.memory.add_insight(
                f"Taxa de fraude: {fraud_indicators['fraud_percentage']:.2f}%",
                "fraud_detection"
            )
        
        self.current_analysis = DataAnalysis(
            summary_stats=summary_stats,
            data_types=data_types,
            missing_values=missing_values,
            correlations=correlations,
            outliers=outliers,
            fraud_indicators=fraud_indicators
        )
        
        print("✅ Análise exploratória concluída")
        return self.current_analysis
    
    def generate_visualization(self, viz_type: str, columns: List[str] = None) -> str:
        """Gera visualizações dos dados"""
        if self.current_df is None:
            return "Erro: Nenhum dataset carregado"
        
        df = self.current_df
        plt.style.use('default')
        
        try:
            if viz_type == "correlation_heatmap":
                numeric_df = df.select_dtypes(include=[np.number])
                if len(numeric_df.columns) > 1:
                    cols_to_plot = numeric_df.columns[:15]
                    
                    plt.figure(figsize=(12, 10))
                    correlation_matrix = numeric_df[cols_to_plot].corr()
                    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, 
                              fmt='.2f', square=True, cbar_kws={'label': 'Correlação'})
                    plt.title('Matriz de Correlação - Agente CSV I2A2', fontsize=16, fontweight='bold')
                    plt.tight_layout()
                    
                    img_buffer = io.BytesIO()
                    plt.savefig(img_buffer, format='png', dpi=150, bbox_inches='tight')
                    img_buffer.seek(0)
                    img_str = base64.b64encode(img_buffer.read()).decode()
                    plt.close()
                    
                    return f"data:image/png;base64,{img_str}"
                else:
                    return "Erro: Não há colunas numéricas suficientes"
            
            elif viz_type == "fraud_analysis" and 'Class' in df.columns:
                fig, axes = plt.subplots(2, 2, figsize=(15, 12))
                
                # Distribuição de classes
                class_counts = df['Class'].value_counts()
                axes[0,0].bar(['Normal', 'Fraude'], [class_counts[0], class_counts[1]], 
                             color=['skyblue', 'salmon'])
                axes[0,0].set_title('Distribuição: Normal vs Fraude', fontweight='bold')
                axes[0,0].set_ylabel('Quantidade')
                
                for i, v in enumerate([class_counts[0], class_counts[1]]):
                    axes[0,0].text(i, v + max(class_counts) * 0.01, f'{v:,}', 
                                  ha='center', va='bottom', fontweight='bold')
                
                # Amount por classe (se existir)
                if 'Amount' in df.columns:
                    df.boxplot(column='Amount', by='Class', ax=axes[0,1])
                    axes[0,1].set_title('Distribuição de Valores por Classe')
                
                # Distribuição temporal
                if 'Time' in df.columns:
                    normal_time = df[df['Class']==0]['Time']
                    fraud_time = df[df['Class']==1]['Time']
                    
                    axes[1,0].hist([normal_time, fraud_time], bins=50, alpha=0.7, 
                                  label=['Normal', 'Fraude'], color=['skyblue', 'salmon'])
                    axes[1,0].set_title('Distribuição Temporal')
                    axes[1,0].legend()
                
                # Correlações com fraude
                numeric_cols = df.select_dtypes(include=[np.number]).columns
                correlations_with_class = df[numeric_cols].corrwith(df['Class']).sort_values(key=abs, ascending=False)
                top_corr = correlations_with_class.head(10)
                
                colors = ['red' if x > 0 else 'blue' for x in top_corr.values]
                axes[1,1].barh(range(len(top_corr)), top_corr.values, color=colors, alpha=0.7)
                axes[1,1].set_yticks(range(len(top_corr)))
                axes[1,1].set_yticklabels(top_corr.index)
                axes[1,1].set_title('Top 10 Correlações com Fraude')
                
                plt.suptitle('Análise de Fraudes - Agente CSV I2A2', fontsize=16, fontweight='bold')
                plt.tight_layout()
                
                img_buffer = io.BytesIO()
                plt.savefig(img_buffer, format='png', dpi=150, bbox_inches='tight')
                img_buffer.seek(0)
                img_str = base64.b64encode(img_buffer.read()).decode()
                plt.close()
                
                return f"data:image/png;base64,{img_str}"
                    
        except Exception as e:
            plt.close('all')
            return f"Erro ao gerar visualização: {str(e)}"
        
        return "Tipo de visualização não reconhecido"
    
    def answer_question(self, question: str) -> Dict[str, Any]:
        """Responde pergunta com reasoning híbrido"""
        if self.current_df is None:
            return {"error": "Nenhum dataset carregado"}
        
        print(f"🤔 Processando: {question[:50]}...")
        
        # EDA se necessário
        if self.current_analysis is None:
            self.perform_eda()
        
        # Preparar contexto para IA
        memory_context = self.memory.get_context()
        
        system_prompt = """Você é um especialista em análise de dados e detecção de fraudes. 
        Analise os dados fornecidos e responda de forma técnica, clara e prática. 
        Forneça insights específicos e recomendações quando apropriado."""
        
        # Preparar dados para a IA
        data_context = f"""
        PERGUNTA: {question}
        
        DADOS DO DATASET:
        - Linhas: {self.current_df.shape[0]:,}
        - Colunas: {self.current_df.shape[1]}
        - Tipos: {self.current_analysis.data_types}
        - Dados faltantes: {self.current_analysis.missing_values}
        - Fraude info: {self.current_analysis.fraud_indicators}
        - Outliers: {self.current_analysis.outliers}
        
        CONTEXTO: {memory_context[:300]}
        
        Responda de forma específica e técnica.
        """
        
        # Usar reasoning híbrido
        ai_response = self.reasoning.query_with_fallback(data_context, system_prompt)
        
        # Verificar se precisa de visualização
        viz_keywords = ["gráfico", "visualização", "chart", "plot", "distribuição", "correlação", "mostrar", "visual"]
        needs_viz = any(keyword in question.lower() for keyword in viz_keywords)
        
        response = {
            "answer": ai_response,
            "visualization": None,
            "data_insights": []
        }
        
        # Gerar visualização se necessário
        if needs_viz:
            if "correlação" in question.lower():
                print("📊 Gerando matriz de correlação...")
                viz_data = self.generate_visualization("correlation_heatmap")
                if viz_data.startswith("data:image"):
                    response["visualization"] = viz_data
            elif any(word in question.lower() for word in ["fraude", "fraud", "class"]) and 'Class' in self.current_df.columns:
                print("🚨 Gerando análise de fraude...")
                viz_data = self.generate_visualization("fraud_analysis")
                if viz_data.startswith("data:image"):
                    response["visualization"] = viz_data
        
        # Insights automáticos
        if self.current_analysis.fraud_indicators:
            fraud_rate = self.current_analysis.fraud_indicators['fraud_percentage']
            response["data_insights"].append(f"Taxa de fraude: {fraud_rate:.2f}%")
            
            if fraud_rate > 1:
                response["data_insights"].append("⚠️ Alta taxa de fraude")
            elif fraud_rate < 0.5:
                response["data_insights"].append("✅ Dataset típico de fraudes (baixa taxa)")
        
        # Adicionar à memória
        self.memory.add_conversation(question, ai_response)
        
        print("✅ Resposta gerada com reasoning híbrido")
        return response
    
    def get_conclusions(self) -> str:
        """Gera conclusões usando reasoning híbrido"""
        if self.current_analysis is None:
            self.perform_eda()
        
        print("🧠 Gerando conclusões com reasoning híbrido...")
        
        system_prompt = """Você é um especialista em análise de dados. Com base na análise completa, 
        forneça conclusões técnicas, insights práticos e recomendações específicas sobre o dataset."""
        
        conclusions_prompt = f"""
        ANÁLISE COMPLETA DO DATASET:
        
        Dados básicos:
        - {self.current_df.shape[0]:,} registros, {self.current_df.shape[1]} colunas
        - Qualidade: {sum(self.current_analysis.missing_values.values())} dados faltantes
        - Fraude: {self.current_analysis.fraud_indicators}
        
        Histórico de análises:
        {self.memory.get_context()}
        
        Forneça conclusões específicas sobre:
        1. Qualidade e características dos dados
        2. Padrões de fraude identificados
        3. Insights técnicos relevantes
        4. Recomendações práticas para uso dos dados
        5. Próximos passos sugeridos
        """
        
        conclusions = self.reasoning.query_with_fallback(conclusions_prompt, system_prompt)
        
        self.memory.add_conversation("Conclusões gerais", conclusions, "conclusions")
        
        print("✅ Conclusões geradas com reasoning híbrido")
        return conclusions
        
    def get_basic_info(self) -> Dict:  # <- MOVER PARA AQUI
        """Retorna informações básicas do dataset"""
        if self.current_df is None:
            return {"error": "Nenhum dataset carregado"}
        
        df = self.current_df
        
        # Informações básicas
        info = {
            "linhas": df.shape[0],
            "colunas": df.shape[1],
            "colunas_nomes": list(df.columns),
            "tipos_dados": {str(k): str(v) for k, v in df.dtypes.to_dict().items()},
            "dados_faltantes": {str(k): int(v) for k, v in df.isnull().sum().to_dict().items()},
            "memoria_mb": float(df.memory_usage(deep=True).sum() / 1024**2)
        }
        
        # Se tem coluna Class (fraude)
        if 'Class' in df.columns:
            fraud_count = df['Class'].sum()
            info["fraude"] = {
                "total_fraudes": int(fraud_count),
                "taxa_fraude": float((fraud_count / len(df)) * 100),
                "distribuicao": {str(k): int(v) for k, v in df['Class'].value_counts().to_dict().items()}
            }
        
        return info

# Função de teste
def test_hybrid_agent():
    """Testa o agente híbrido"""
    print("🤖 Testando Agente CSV Híbrido I2A2")
    print("=" * 50)
    
    # Tentar carregar chave OpenAI do ambiente
    openai_key = os.getenv('OPENAI_API_KEY')
    if not openai_key:
        print("💡 Para usar OpenAI, defina: export OPENAI_API_KEY=sua_chave")
        print("💡 Ou crie arquivo .env com OPENAI_API_KEY=sua_chave")
    
    agent = CSVAgentHybrid(openai_api_key=openai_key)
    
    test_file = "../creditcard.csv"
    
    if os.path.exists(test_file):
        print(f"📁 Testando com: {test_file}")
        success = agent.load_csv(test_file)
        
        if success:
            print("✅ CSV carregado com sucesso")
            
            # Teste com reasoning híbrido
            response = agent.answer_question("Quais são as principais características deste dataset de fraudes?")
            print(f"🤖 Resposta com reasoning: {response['answer'][:300]}...")
            
        else:
            print("❌ Erro ao carregar CSV")
    else:
        print(f"❌ Arquivo não encontrado: {test_file}")
    
    return agent

if __name__ == "__main__":
    test_hybrid_agent()
